import vertexai
from vertexai.generative_models import GenerativeModel as AIModel
from typing import Final

# --- CONFIGURATION SETTINGS ---
PROJECT_ID: Final[str] = "PASTE_ID_HERE"
LOCATION: Final[str] = "PASTE_REGION_HERE"
MODEL_NAME: Final[str] = "gemini-2.5-flash-lite"
# ------------------------------

class InterviewConsultant:
    def __init__(self):
        """Prepares the Vertex AI connection using global config."""
        vertexai.init(project=PROJECT_ID, location=LOCATION)
        self.generator = AIModel(MODEL_NAME)

    def fetch_answer(self, query_text: str) -> str:
        """Triggers the model to produce a text-based response."""
        execution = self.generator.generate_content(query_text)
        return execution.text

def run_interface():
    # Setup visual constants
    border = "*" * 65
    fallback_prompt = "Give me ten interview questions for the role of program manager."

    # Capture user input
    user_entry = input("Input your prompt (Enter for default): ").strip()
    active_prompt = user_entry or fallback_prompt

    # Initialize and execute
    consultant = InterviewConsultant()
    
    print(f"\n{border}\nGENERATED CONTENT:\n")
    print(consultant.fetch_answer(active_prompt))
    print(f"\n{border}")

if __name__ == "__main__":
    run_interface()